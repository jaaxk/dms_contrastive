# -*- coding: utf-8 -*-
"""dms_cosine_jv.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PJEilEw4yQiz4Y8PgGoiay8RDkPvwIsQ
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
import warnings
import sys
import esm
from tqdm import tqdm
import pickle
import os
import argparse
from transformers import AutoTokenizer, AutoModel
import scripts.h5_utils as h5_utils
import json
import re
from contextlib import redirect_stdout, redirect_stderr
from scripts.metrics import contrastive_metrics, kmeans_metrics, logreg_metrics, knn_metrics, ridge_metrics

warnings.filterwarnings('ignore')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

def parse_args():
    parser = argparse.ArgumentParser(
        prog='DMS_contrastive',
        description='DMS contrastive learning pipeline'
    )

    parser.add_argument('--run_name', type=str, required=True)

    #ML hyperparams
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--learning_rate', type=float, default=0.0001)
    parser.add_argument('--num_epochs', type=int, default=200)
    parser.add_argument('--patience', type=int, default=50)
    parser.add_argument('--distance_metric', choices=['cosine', 'euclidean'], default='cosine')
    parser.add_argument('--use_learnable', type=bool, default=False)

    #model hyperparams
    parser.add_argument('--hidden_dims', type=list, default=[512, 256, 128])
    parser.add_argument('--normalize_output', type=bool, default=True)
    parser.add_argument('--freeze_esm', action='store_true', default=False)
    parser.add_argument('--esm_layer', type=int, default=33)
    parser.add_argument('--model_name', default='facebook/esm2_t33_650M_UR50D', help='ESM model name (start with facebook/)')

    #data
    parser.add_argument('--embeddings_path', default=None)
    parser.add_argument('--ohe_embeddings_path', default=None)
    parser.add_argument('--data_path', default='dms_data/datasets/Stability.csv')
    parser.add_argument('--split_by_gene', action='store_true', help='train/test split by gene rather than variant')
    parser.add_argument('--split_by_position', action='store_true', help='if not splitting by gene, whether to split by position (True) or randomly by sequence (False)')
    parser.add_argument('--base_results_dir', default='results')
    parser.add_argument('--same_gene_batch', action='store_true', help='each batch contains a single gene, no cross-gene pairs', default=False)
    parser.add_argument('--model_cache', default=None)
    parser.add_argument('--esm_max_length', type=int, default=75)
    parser.add_argument('--input_dim', type=int, default=1280)
    parser.add_argument('--dropout', type=float, default=0.1)
    parser.add_argument('--metadata_path', default=None)
    parser.add_argument('--normalize_to_wt', action='store_true', default=False)
    parser.add_argument('--ohe_baseline', action='store_true', default=False)
    parser.add_argument('--model_path', type=str, default=None, help='path to pre-trained PROJECTION HEAD')
    parser.add_argument('--esm_variants_module_path', default='/gpfs/home/jv2807/dms_contrastive/esm-variants')
    parser.add_argument('--gene_split_file', type=str, default=None, help='path to json file specifying gene train/test split')

    args = parser.parse_args()
    print(args)
    return args

args = parse_args()

#EMBEDDINGS_PATH = args.embeddings_path
DATA_PATH = args.data_path
RUN_NAME = args.run_name

#params
BATCH_SIZE = args.batch_size
LEARNING_RATE = args.learning_rate
NUM_EPOCHS = args.num_epochs
PATIENCE = args.patience
DISTANCE_METRIC = args.distance_metric
USE_LEARNABLE = args.use_learnable

# Model architecture
HIDDEN_DIMS = args.hidden_dims
NORMALIZE_OUTPUT = args.normalize_output

if args.model_cache is not None:
    torch.hub.set_dir(args.model_cache)
#results dir
RESULTS_DIR = f'{args.base_results_dir}/{args.run_name}'

#pre-set model_path if model and data_split already exist
if args.model_path is None:
    if os.path.exists(RESULTS_DIR+'/projection_head.pt') and os.path.exists(RESULTS_DIR+'/data_split.json'):
        args.model_path = RESULTS_DIR+'/projection_head.pt'
        print(f"Pre-trained model found at {args.model_path}, setting --model_path accordingly")
    else:
        print("No pre-trained model found")
       
os.makedirs(RESULTS_DIR, exist_ok=True)
json.dump(vars(args), open(f'{RESULTS_DIR}/args.json', 'w'))
os.makedirs(f'{RESULTS_DIR}/training_figs', exist_ok=True)
RESULTS_FILE = f'{args.base_results_dir}/results.csv'
if not os.path.exists(RESULTS_FILE):
    with open(RESULTS_FILE, 'w') as f:
        f.write('run_name,test_loss,test_acc,test_precision,test_recall,test_f1,test_auc\n')

if args.normalize_to_wt:
    if not args.metadata_path:
        raise ValueError("--metadata_path must be specified if --normalize_to_wt is set")
    
#init ESM model
if args.model_path is None:
    esm_model = AutoModel.from_pretrained(args.model_name)
    tokenizer = AutoTokenizer.from_pretrained(args.model_name)
    esm_model.eval() #REMOVE once we are finetuning
    esm_model.to(device)
else:
    esm_model = None
    tokenizer = None


if args.ohe_baseline:
    repo_path = os.path.abspath(args.esm_variants_module_path)
    if not os.path.exists(repo_path):
        raise ValueError(f"ESM-variants repository not found at {repo_path}, run 'git clone https://github.com/ntranoslab/esm-variants , then set --esm_variants_module_path to the repo.")
    sys.path.append(repo_path)
    import esm_variants_utils

    #load model
    esm_model_llr, esm_alphabet_llr = esm.pretrained.esm2_t33_650M_UR50D()
    esm_batch_converter_llr = esm_alphabet_llr.get_batch_converter()

ESMEmbeddingLoader = None
OHEEmbeddingLoader = None

if args.model_path is not None:
    DATA_SPLIT_PATH = f'{os.path.dirname(args.model_path)}/data_split.json'
    if not os.path.exists(DATA_SPLIT_PATH):
        raise ValueError(f"Data split file not found at {DATA_SPLIT_PATH}, cannot load embeddings for evaluation - bypass this if you want to evaluate a model on a different split (BUT BE AWARE OF DATA LEAKAGE!)")
else:
    DATA_SPLIT_PATH = None

# Set all random seeds for reproducibility
def set_seed(seed=42):
    import random
    import numpy as np
    import torch
    import os
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)

def esm_batch(sequences):
    print('ESM BATCH METHOD')
    tokenized = tokenizer(sequences, padding=True, truncation=True, max_length=args.esm_max_length, return_tensors="pt")
    batch_tokens = tokenized['input_ids'].to(device)
    attention_mask = tokenized['attention_mask'].to(device)
    with torch.no_grad(): #remove this once we're ready to finetune
        results = esm_model(input_ids=batch_tokens, attention_mask=attention_mask, output_hidden_states=False)
    reps = results["last_hidden_state"].to(device)    
    #mean pooling
    mask = attention_mask.unsqueeze(-1)          # (B, L, 1)
    masked_reps = reps * mask
    sum_reps = masked_reps.sum(dim=1)
    lengths = mask.sum(dim=1)
    embeddings_batch = sum_reps / lengths         # (B, H)
    out = embeddings_batch

    return out

class DMSContrastiveDataset(Dataset):
    def __init__(self, sequences, quartiles, dms_scores, genes, mutants=None):
        self.sequences = sequences
        self.quartiles = quartiles
        self.dms_scores = dms_scores
        #self.seq_to_embedding = seq_to_embedding
        self.genes = genes
        self.mutants = mutants

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        sequence = self.sequences[idx]
        quartile = self.quartiles[idx]
        dms_score = self.dms_scores[idx]
        gene = self.genes[idx]
        mutant = self.mutants[idx] if self.mutants is not None else None

        #get precomputed embedding
        #emb = self.seq_to_embedding[seq]

        return {
            'quartile': quartile,
            'dms_score': dms_score,
            'sequence': sequence,
            'gene': gene,
            'mutant': mutant
        }

def load_embeddings_h5(sequences, embedding_loader, embedding_type, mutants=None, wt_seqs=None):
    if embedding_loader is None:
        raise ValueError("embedding_loader must be specified")
    if embedding_type not in ['esm', 'ohe']:
        raise ValueError("embedding_type must be 'esm' or 'ohe'")
        
    embeddings, missing_seqs, missing_indices = embedding_loader.load_embeddings(sequences)
    assert len(missing_seqs) == len(missing_indices)
    
    if len(missing_seqs) > 0:
        if embedding_type == 'esm':
            missing_embeddings = esm_batch(missing_seqs)
        elif embedding_type == 'ohe':
            all_embeddings = get_ohe_features(wt_seqs, mutants)
            missing_embeddings = torch.Tensor(all_embeddings[missing_indices])
        
        embedding_loader.save_embeddings(missing_seqs, missing_embeddings)
        #insert missing embeddings back into embeddings
        for i, idx in enumerate(missing_indices):
            embeddings[idx] = missing_embeddings[i]


    embeddings = torch.stack([
        torch.as_tensor(e, dtype=torch.float32).to(device)
        for e in embeddings
    ])

    return embeddings

class DataLoader():
    def __init__(self, dataset, batch_size=16, shuffle=True, balance_quartiles=True, gene_to_wt=None, gene_aware=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.balance_quartiles = balance_quartiles
        self.gene_to_wt = gene_to_wt
        self.gene_aware = gene_aware

        if gene_aware:
            self.gene_groups = {}
            for i, gene in enumerate(dataset.genes):
                if gene not in self.gene_groups:
                    self.gene_groups[gene] = {'high': [], 'low': []}
                quartile = dataset.quartiles[i]
                self.gene_groups[gene][quartile].append(i)

            print(f"Gene-aware loader created for {len(self.gene_groups)} genes")
            for gene, quartile_dict in list(self.gene_groups.items())[:3]:
                print(f"  {gene}: {len(quartile_dict['high'])} high, {len(quartile_dict['low'])} low")
        else:
            print('Using basic data loader - no gene grouping')
        
        # Standard behavior - no gene grouping
        self.indices = list(range(len(dataset)))
        if self.shuffle:
            np.random.shuffle(self.indices)

    def __iter__(self):
        # Separate indices by quartile
        if self.gene_aware:
            all_batches = []

            for gene, quartile_dict in self.gene_groups.items():
                high_indices = quartile_dict['high'].copy()
                low_indices = quartile_dict['low'].copy()

                if self.shuffle:
                    np.random.shuffle(high_indices)
                    np.random.shuffle(low_indices)

                if self.balance_quartiles and len(high_indices) > 0 and len(low_indices) > 0:
                    half_batch = self.batch_size // 2

                    num_batches = min(len(high_indices) // half_batch, len(low_indices) // half_batch)

                    for i in range(num_batches):
                        batch_high = high_indices[i*half_batch:(i+1)*half_batch]
                        batch_low = low_indices[i*half_batch:(i+1)*half_batch]
                        batch_indices = batch_high + batch_low

                        if self.shuffle:
                            np.random.shuffle(batch_indices)

                        batch = [self.dataset[idx] for idx in batch_indices]
                        all_batches.append(batch)

            if self.shuffle:
                np.random.shuffle(all_batches)

            for batch in all_batches:
                yield self._collate_batch(batch)

        else:

            high_indices = [i for i, q in enumerate(self.dataset.quartiles) if q == 'high']
            low_indices = [i for i, q in enumerate(self.dataset.quartiles) if q == 'low']
            
            if self.shuffle:
                np.random.shuffle(high_indices)
                np.random.shuffle(low_indices)
            
            # Determine the number of batches we can make
            half_batch = self.batch_size // 2
            num_batches = min(len(high_indices), len(low_indices)) // half_batch
            
            for i in range(num_batches):
                # Take equal number of high and low quartile samples
                batch_high = high_indices[i*half_batch:(i+1)*half_batch]
                batch_low = low_indices[i*half_batch:(i+1)*half_batch]
                batch_indices = batch_high + batch_low
                
                # Shuffle the combined batch
                if self.shuffle:
                    np.random.shuffle(batch_indices)
                    
                batch = [self.dataset[idx] for idx in batch_indices]
                yield self._collate_batch(batch)

    def _collate_batch(self, batch):
        #embeddings = torch.stack([item['embedding'] for item in batch])
        quartiles = [item['quartile'] for item in batch]
        dms_scores = [item['dms_score'] for item in batch]
        sequences = [item['sequence'] for item in batch]
        genes = [item['gene'] for item in batch]

        if args.normalize_to_wt:
            wt_sequences = [self.gene_to_wt[gene] for gene in genes]
            wt_embeddings = load_embeddings_h5(wt_sequences, embedding_loader=ESMEmbeddingLoader, embedding_type='esm')
        else:
            wt_embeddings = None

        if args.ohe_baseline and self.gene_aware:
            #print('gene-aware ohe batch iteration')
            mutants = [item['mutant'] for item in batch]
            ohe_features = load_embeddings_h5(sequences, embedding_loader=OHEEmbeddingLoader, embedding_type='ohe', mutants=mutants, wt_seqs=wt_sequences)
        else:
            ohe_features = None
            mutants = None

        embeddings = load_embeddings_h5(sequences, embedding_loader=ESMEmbeddingLoader, embedding_type='esm')

        return {
            'quartiles': quartiles,
            'dms_scores': dms_scores,
            'sequences': sequences,
            'genes': genes,
            'wt_embeddings': wt_embeddings,
            'embeddings': embeddings,
            'ohe_features': ohe_features,
            'mutants': mutants
        }

    def __len__(self):
        return len(self.indices) // self.batch_size

class ContrastiveNetwork(nn.Module):
    def __init__(self, input_dim=1280, hidden_dims=[512, 256, 128], normalize_output=False, esm_layer=33, esm_only=False, normalize_to_wt=False):
        super(ContrastiveNetwork, self).__init__()

        if esm_layer != 33:
            raise ValueError('change forward method to output all hidden states')
        
        self.esm_layer = esm_layer
        self.esm_only = esm_only
        self.normalize_to_wt = normalize_to_wt

        layers = []
        prev_dim = input_dim

        layers.append(nn.Dropout(args.dropout))

        for i, hidden_dim in enumerate(hidden_dims):
            layers.append(nn.Linear(prev_dim, hidden_dim))

            if i < len(hidden_dims) - 1:
                layers.append(nn.LayerNorm(hidden_dim))
                layers.append(nn.ReLU())

            prev_dim = hidden_dim

        self.projection = nn.Sequential(*layers)
        self.normalize_output = normalize_output

    def forward(self, batch):

        out = batch['embeddings']

        if self.normalize_to_wt:
            out = out - batch['wt_embeddings']

        if self.esm_only:
            x = out
        else:
            x = self.projection(out) 
        
        if self.normalize_output:
            #l2 normalize
            x = nn.functional.normalize(x, p=2, dim=-1)
        return x

        """#print('forward 1'
        out = batch['embeddings']
        #reps = out["representations"][self.esm_layer]
        #embs = reps.mean(dim=1) #mean pool
        x = self.projection(out) 
        if self.normalize_output:
            #l2 normalize
            x = nn.functional.normalize(x, p=2, dim=-1)
        return x"""

class ContrastiveLoss(nn.Module):
    def __init__(self, distance_metric="cosine", use_learnable=True):
        super(ContrastiveLoss, self).__init__()
        self.distance_metric = distance_metric
        self.use_learnable = use_learnable

        if use_learnable:
            if distance_metric == "euclidean":
                self.alpha = nn.Parameter(torch.tensor(-10.0))
            else:  #cosine
                #positive: high similarity → high probability
                self.alpha = nn.Parameter(torch.tensor(10.0))
            self.beta = nn.Parameter(torch.tensor(0.0))

    def forward(self, embeddings, quartiles):
        batch_size = embeddings.shape[0]
        device = embeddings.device

        if self.distance_metric == "euclidean":
            norms = (embeddings ** 2).sum(dim=1, keepdim=True)  # (B, 1)
            distance_matrix = norms + norms.t() - 2 * torch.mm(embeddings, embeddings.t())
            distance_matrix = torch.sqrt(torch.clamp(distance_matrix, min=1e-8))  # (B, B)

            if self.use_learnable:
                logit_matrix = self.alpha * distance_matrix + self.beta
                similarity_matrix = torch.sigmoid(logit_matrix)
            else:
                similarity_matrix = torch.exp(-distance_matrix)
                similarity_matrix = torch.clamp(similarity_matrix, min=1e-7, max=1-1e-7)

        elif self.distance_metric == "cosine":
            embeddings_norm = nn.functional.normalize(embeddings, p=2, dim=1)  # (B, D)

            #pairwise cosine similarity: normalized dot products
            cosine_sim_matrix = torch.mm(embeddings_norm, embeddings_norm.t())  # (B, B)

            #distance = 1 - cosine_sim
            distance_matrix = 1 - cosine_sim_matrix

            if self.use_learnable:
                logit_matrix = self.alpha * cosine_sim_matrix + self.beta
                similarity_matrix = torch.sigmoid(logit_matrix)
            else:
                # Fixed transformation: map [-1, 1] to [0, 1]
                similarity_matrix = (cosine_sim_matrix * 0.5) + 0.5
                similarity_matrix = torch.clamp(similarity_matrix, min=1e-7, max=1-1e-7)
        else:
            raise ValueError(f"Unknown distance metric: {self.distance_metric}")

        #create label matrix: 1 if same quartile, 0 if different
        quartile_tensor = torch.tensor([1 if q == 'high' else 0 for q in quartiles],
                                       dtype=torch.long, device=device)
        label_matrix = (quartile_tensor.unsqueeze(0) == quartile_tensor.unsqueeze(1)).float()

        #extract upper triangle (excluding diagonal) for pairs
        upper_triangle_mask = torch.triu(torch.ones_like(label_matrix), diagonal=1).bool()

        similarities = similarity_matrix[upper_triangle_mask]
        labels = label_matrix[upper_triangle_mask]
        distances = distance_matrix[upper_triangle_mask]

        #compute loss
        loss = nn.BCELoss()(similarities, labels)

        all_similarities = similarities.detach().cpu().tolist()
        all_distances = distances.detach().cpu().tolist()
        all_labels = labels.cpu().tolist()

        return loss, all_similarities, all_distances, all_labels

def load_and_preprocess_data(data_path):
    print(f"Loading data from {data_path}")
    df = pd.read_csv(data_path)

    df = df.dropna(subset=['DMS_score', 'mutated_sequence', 'filename'])

    #get unique genes
    unique_genes = df['filename'].unique()
    print(f"Found {len(unique_genes)} unique genes")

    #process each gene separately (gene-aware quartile calculation)
    all_processed_dfs = []

    for gene in unique_genes:
        gene_df = df[df['filename'] == gene].copy()

        if len(gene_df) < 10:
            print(f"Skipping gene {gene} (only {len(gene_df)} samples)")
            continue

        #calculate quartiles for THIS gene
        q25 = gene_df['DMS_score'].quantile(0.25)
        q75 = gene_df['DMS_score'].quantile(0.75)

        #filter to top 75% and bottom 25% for this gene
        top_75 = gene_df[gene_df['DMS_score'] >= q75].copy()
        bottom_25 = gene_df[gene_df['DMS_score'] <= q25].copy()

        #add quartile labels
        top_75['quartile'] = 'high'
        bottom_25['quartile'] = 'low'

        #combine for this gene
        gene_processed = pd.concat([top_75, bottom_25], ignore_index=True)
        all_processed_dfs.append(gene_processed)

        print(f"  {gene}: {len(gene_processed)} samples (high: {len(top_75)}, low: {len(bottom_25)})")

    #combine all genes
    combined_df = pd.concat(all_processed_dfs, ignore_index=True)
    print(f"\n Total processed samples: {len(combined_df)}")

    return combined_df

def create_train_test_split(df, split_by_gene=True, split_by_position=None, test_size=0.2):
    print("\nCreating gene-aware train/test split...")

    #get unique sequences
    all_sequences = df['mutated_sequence'].unique()
    print(f"Total unique sequences: {len(all_sequences)}")

    #get unique genes
    all_genes = df['uniprot_id'].unique()
    print(f"Total unique genes: {len(all_genes)}")

    if split_by_gene:
        print('Splitting by gene...')
        if DATA_SPLIT_PATH is not None and os.path.exists(DATA_SPLIT_PATH):
            print(f"Loading gene split from {DATA_SPLIT_PATH}")
            with open(DATA_SPLIT_PATH, 'r') as f:
                split_to_genes = json.load(f)
            train_genes = np.array(split_to_genes['train'])
            test_genes = np.array(split_to_genes['test'])
        else:
            print('WARNING: Not using pre-defined gene split file - creating new random split')
            train_genes, test_genes = train_test_split(all_genes, test_size=test_size, random_state=42)
            split_to_genes = {'train': train_genes.tolist(), 'test': test_genes.tolist()}
            with open(f'{RESULTS_DIR}/data_split.json', 'w') as f:
                json.dump(split_to_genes, f)

        print(f"Train genes: {len(train_genes)}")
        print(f"Test genes: {len(test_genes)}")

        #create train/test dataframes
        train_df = df[df['uniprot_id'].isin(train_genes)].copy()
        test_df = df[df['uniprot_id'].isin(test_genes)].copy()
        
        train_sequences = train_df['mutated_sequence']
        test_sequences = test_df['mutated_sequence']

    else:
        if split_by_position is None:
            raise ValueError("split_by_position (boolean) must be specified if split_by_gene is False")
        
        if DATA_SPLIT_PATH is not None and os.path.exists(DATA_SPLIT_PATH):
            with open(DATA_SPLIT_PATH, 'r') as f:
                split_to_sequences = json.load(f)
            try:
                train_sequences = split_to_sequences['train_sequences']
                test_sequences = split_to_sequences['test_sequences']
            except KeyError:
                raise ValueError(f"Data split file at {DATA_SPLIT_PATH} does not contain 'train_sequences' and 'test_sequences' keys required for sequence-based split")
            print(f"Loaded pre-defined sequence split from {DATA_SPLIT_PATH}")
            train_df = df[df['mutated_sequence'].isin(train_sequences)].copy()
            test_df = df[df['mutated_sequence'].isin(test_sequences)].copy()
            train_genes = train_df['uniprot_id']
            test_genes = test_df['uniprot_id']


        if split_by_position:
            print('Splitting by position...')
            MISSENSE_PATTERN = re.compile('([A-Z])(\d+)([A-Z])')
            train_sequences = []
            test_sequences = []
            for gene in all_genes:
                gene_df = df[df['uniprot_id'] == gene]
                positions = []
                for mut in gene_df['mutant']:
                    matches = MISSENSE_PATTERN.findall(mut)
                    if not matches:
                        continue
                    ref_aa, pos, alt_aa = matches[0] #only get first one if there are multiple
                    positions.append(int(pos))

                unique_positions = list(set(positions))
                np.random.shuffle(unique_positions)
                train_positions = unique_positions[:int(len(unique_positions)*(1.0 - test_size))]
                test_positions = unique_positions[int(len(unique_positions)*(1.0 - test_size)):]

                for i, seq in enumerate(gene_df['mutated_sequence']):
                    if positions[i] in train_positions:
                        train_sequences.append(seq)
                    elif positions[i] in test_positions:
                        test_sequences.append(seq)
                if len(train_sequences) == 0 or len(test_sequences) == 0:
                    print(f"Skipping gene {gene} for random split due to insufficient data after sampling")
                    continue
           
            train_df = df[df['mutated_sequence'].isin(train_sequences)].copy()
            test_df = df[df['mutated_sequence'].isin(test_sequences)].copy()

            train_genes = train_df['uniprot_id']
            test_genes = test_df['uniprot_id']
            

        else:
            print('Splitting by sequence, NOT position-aware...')
            #split sequences
            train_sequences, test_sequences = train_test_split(
                all_sequences, test_size=test_size, random_state=42
            )

            print(f"Train sequences: {len(train_sequences)}")
            print(f"Test sequences: {len(test_sequences)}")

            #create train/test dataframes
            train_df = df[df['mutated_sequence'].isin(train_sequences)].copy()
            test_df = df[df['mutated_sequence'].isin(test_sequences)].copy()

            #get genes
            train_genes = train_df['uniprot_id']
            test_genes = test_df['uniprot_id']

        #save split to json
        split_to_sequences = {
            'train_sequences': train_sequences,
            'test_sequences': test_sequences
        }
        with open(f'{RESULTS_DIR}/data_split.json', 'w') as f:
            json.dump(split_to_sequences, f)


    print(f"Train samples: {len(train_df)}")
    print(f"Test samples: {len(test_df)}")

    #verify no GENE overlap
    overlap = set(train_genes).intersection(set(test_genes))
    if len(overlap) == 0:
        print("✅ No gene overlap between train and test - proper held-out test!")
    else:
        print(f"⚠️  Warning: {len(overlap)} genes overlap")
        if args.split_by_gene:
            raise ValueError("Gene overlap detected in gene-aware split")

    #verify no SEQUENCE overlap
    overlap = set(train_sequences).intersection(set(test_sequences))
    if len(overlap) == 0:
        print("✅ No sequence overlap between train and test - proper held-out test!")
    else:
        print(f"⚠️  Warning: {len(overlap)} sequences overlap")
        raise ValueError("Sequence overlap detected in sequence-aware split")

    return train_df, test_df

def get_embeddings_from_model(projection_net, dataloader, device):
    projection_net.eval()
    
    all_projections = []
    
    with torch.no_grad():
        for batch in tqdm(dataloader):
            sequences = batch['sequences'].to(device)
            projected = projection_net(sequences)
            all_projections.extend(projected.cpu().detach().numpy())
    
    return all_projections

def train_epoch(projection_net, loss_fn, dataloader, optimizer, device):
    projection_net.train()

    total_loss = 0
    all_similarities = []
    all_labels = []
    all_distances = []
    all_projections = []
    all_quartiles = []
    num_batches = 0

    for batch in tqdm(dataloader, desc="Training"):
        optimizer.zero_grad()

        #sequences = batch['sequences']
        quartiles = batch['quartiles']

        #project embeddings
        projected = projection_net(batch)
        all_projections.extend(projected.cpu().detach().numpy())

        #compute loss
        loss, similarities, distances, labels = loss_fn(projected, quartiles)

        #backward pass
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        num_batches += 1

        all_similarities.extend(similarities)
        all_distances.extend(distances)
        all_labels.extend(labels)
        all_quartiles.extend(quartiles)

    return total_loss / max(num_batches, 1), all_similarities, all_labels, all_distances, all_quartiles, all_projections

def evaluate_model(projection_net, loss_fn, dataloader, device):
    projection_net.eval()

    all_similarities = []
    all_labels = []
    all_distances = []
    all_kmeans_labels = []
    all_quartiles = []
    all_projections = []
    total_loss = 0
    num_batches = 0

    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluation"):
            quartiles = batch['quartiles']

            #project embeddings
            projected = projection_net(batch)
            all_projections.extend(projected.cpu().detach().numpy())

            #compute loss
            loss, similarities, distances, labels = loss_fn(projected, quartiles)

            total_loss += loss.item()
            num_batches += 1

            all_similarities.extend(similarities)
            all_distances.extend(distances)
            all_labels.extend(labels)
            all_quartiles.extend(quartiles)

    avg_loss = total_loss / max(num_batches, 1)
    return avg_loss, all_similarities, all_labels, all_distances, all_quartiles, all_projections


def plot_training_metrics(train_losses, val_losses, train_aucs, val_aucs):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    #loss plot
    ax1.plot(train_losses, label='Train Loss', color='blue')
    ax1.plot(val_losses, label='Val Loss', color='red')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Validation Loss (Cosine Similarity)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    #accuracy plot
    ax2.plot(train_aucs, label='Train AUC', color='blue')
    ax2.plot(val_aucs, label='Val AUC', color='red')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('AUC')
    ax2.set_title('Training and Validation AUC')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(f'{RESULTS_DIR}/training_metrics.png')

def plot_distance_clustering(distances, labels, title="Distance Clustering", final=False):
    similar_distances = [d for d, l in zip(distances, labels) if l == 1]
    dissimilar_distances = [d for d, l in zip(distances, labels) if l == 0]

    plt.figure(figsize=(12, 5))

    #histogram comparison
    plt.subplot(1, 2, 1)
    plt.hist(similar_distances, bins=30, alpha=0.7, label='Similar (1)', color='blue', density=True)
    plt.hist(dissimilar_distances, bins=30, alpha=0.7, label='Dissimilar (0)', color='red', density=True)
    plt.xlabel('Cosine Distance (1 - cosine_sim)')
    plt.ylabel('Density')
    plt.title(f'{title} - Distribution')
    plt.legend()
    plt.grid(True, alpha=0.3)

    #box plot comparison
    plt.subplot(1, 2, 2)
    data_to_plot = [similar_distances, dissimilar_distances]
    box_plot = plt.boxplot(data_to_plot, labels=['Similar (1)', 'Dissimilar (0)'],
                          patch_artist=True, showfliers=True)
    box_plot['boxes'][0].set_facecolor('lightblue')
    box_plot['boxes'][1].set_facecolor('lightcoral')
    plt.ylabel('Cosine Distance')
    plt.title(f'{title} - Box Plot')
    plt.grid(True, alpha=0.3)

    #add statistics
    similar_mean = np.mean(similar_distances)
    dissimilar_mean = np.mean(dissimilar_distances)
    separation = dissimilar_mean - similar_mean

    plt.figtext(0.5, 0.02,
                f'Similar mean: {similar_mean:.4f} | Dissimilar mean: {dissimilar_mean:.4f} | Separation: {separation:.4f}',
                ha='center', fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))

    plt.tight_layout()
    if final:
        plt.savefig(f'{RESULTS_DIR}/{title}.png')
    else:
        plt.savefig(f'{RESULTS_DIR}/training_figs/{title}.png')

    return similar_mean, dissimilar_mean, separation

def visualize_embeddings_tsne(embeddings, labels, title="t-SNE Visualization"):
    print(f"Creating t-SNE visualization: {title}")

    #reduce dimensionality
    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings)-1))
    embeddings_2d = tsne.fit_transform(embeddings.cpu().numpy())

    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],
                         c=labels, cmap='viridis', alpha=0.7, s=50)
    plt.colorbar(scatter, label='DMS Score')
    plt.title(title)
    plt.xlabel('t-SNE 1')
    plt.ylabel('t-SNE 2')
    plt.tight_layout()
    plt.savefig(f'{RESULTS_DIR}/{title}.png')

def calc_esm_llr_scores(wt_seq):
    _, (raw_llr_scores,) = esm_variants_utils.get_wt_LLR(pd.DataFrame([{'id': '_', 'gene': '_', 'seq': wt_seq, 'length': len(wt_seq)}]), \
            esm_model_llr, esm_alphabet_llr, esm_batch_converter_llr, device="cpu")
    raw_seq_results = raw_llr_scores.transpose().stack().reset_index().rename(columns = {'level_0': 'wt_aa_and_pos', 'level_1': 'mut_aa', \
            0: 'esm_score'})
    return pd.DataFrame({'mut_name': raw_seq_results['wt_aa_and_pos'].str.replace(' ', '') + raw_seq_results['mut_aa'], \
            'esm_score': raw_seq_results['esm_score']}).set_index('mut_name')['esm_score']


def ohe_llr_baseline(batches, projection_net, train_size=None):
    #returns average of gene-level metrics across genes in dataloader: should be TEST loader because projection head is trained on train loader
    #evaluate baseline and projection model on same dataset using knn/ridge
    print("Calculating OHE LLR baseline")

    #all_losses = []
    #all_similarities = []
    #all_distances = []
    #all_labels = []

    gene_to_metrics = {'baseline': {'random_split': {}, 'positional_split': {}}, 'projections': {'random_split': {}, 'positional_split': {}}}
    current_gene = None
    
    for batch in tqdm(batches, desc="evaluating batches"):
        quartiles = batch['quartiles']
        ohe_features = batch['ohe_features'].cpu()
        projections = batch['projections']
        #projections = projection_net(batch).cpu().detach().numpy()
        mutants = batch['mutants']

        assert len(set(batch['genes'])) == 1 #should only be used with gene-aware loader
        gene = batch['genes'][0]

        if gene != current_gene:
            #evaluate last gene
            if current_gene is not None:
                should_evaluate=True
                #train/test split
                #POSITIONAL SPLIT
                MISSENSE_PATTERN = re.compile('([A-Z])(\d+)([A-Z])')
                positions = []
                position_indices = []  # Track which encodings have valid positions
                for i, mut in enumerate(gene_mutants):
                    matches = MISSENSE_PATTERN.findall(mut)
                    if not matches:
                        continue
                    ref_aa, pos, alt_aa = matches[0]
                    positions.append(int(pos))
                    position_indices.append(i)  # Remember which index this came from
                if (len(gene_mutants) - len(positions)) > 0:
                    print(f'Removed {len(gene_mutants) - len(positions)} mutations that did not match the expected pattern')

                unique_positions = list(set(positions))
                np.random.shuffle(unique_positions)
                train_positions = unique_positions[:int(len(unique_positions)*0.8)]
                test_positions = unique_positions[int(len(unique_positions)*0.8):]

                train_idx = []
                test_idx = []
                for idx, pos in zip(position_indices, positions):
                    if pos in train_positions:
                        train_idx.append(idx)
                    elif pos in test_positions:
                        test_idx.append(idx)

                #sample train set size if specified
                if train_size is not None and len(train_idx) > train_size:
                    if train_size <= 1: #handle fraction
                        train_num = int(len(train_idx) * train_size)
                    else:
                        train_num = train_size
                    train_idx = np.random.choice(train_idx, size=train_num, replace=False).tolist()

                if len(train_idx) == 0 or len(test_idx) == 0:
                    print(f"Skipping gene {current_gene} for positional split due to insufficient data after sampling")
                    should_evaluate=False

                train_encodings = [gene_encodings[i] for i in train_idx]
                train_projections = [gene_projections[i] for i in train_idx]
                train_quartiles = [gene_quartiles[i] for i in train_idx]
                
                if len(train_encodings) < 5:
                    print(f"Skipping gene {current_gene} for positional split due to insufficient training data")
                    should_evaluate=False
                    
            
                #train_similarities = [gene_similarities[i] for i in train_idx]
                #train_labels = [gene_labels[i] for i in train_idx]
                
                test_encodings = [gene_encodings[i] for i in test_idx]
                test_projections = [gene_projections[i] for i in test_idx]
                test_quartiles = [gene_quartiles[i] for i in test_idx]
                #test_similarities = [gene_similarities[i] for i in test_idx]
                #test_labels = [gene_labels[i] for i in test_idx]

                if len(set(train_quartiles)) < 2 or len(set(test_quartiles)) < 2:
                    print(f"Skipping gene {current_gene} for positional split due to only one quartile present in train or test set")
                    should_evaluate=False

                #baseline results
                if should_evaluate:
                    results = {'knn': [], 'ridge': []}
                    #knn eval:
                    accuracy, precision, recall, f1, auc = knn_metrics(test_encodings, test_quartiles, train_encodings, train_quartiles)
                    results['knn'] = [accuracy, precision, recall, f1, auc]
                    #ridge eval:
                    accuracy, precision, recall, f1, auc = ridge_metrics(train_encodings, train_quartiles, test_encodings, test_quartiles)
                    results['ridge'] = [accuracy, precision, recall, f1, auc]
                    gene_to_metrics['baseline']['positional_split'][current_gene] = results

                    #projection results
                    results = {'knn': [], 'ridge': []}
                    #knn eval:
                    accuracy, precision, recall, f1, auc = knn_metrics(test_projections, test_quartiles, train_projections, train_quartiles)
                    results['knn'] = [accuracy, precision, recall, f1, auc]
                    #ridge eval:
                    accuracy, precision, recall, f1, auc = ridge_metrics(train_projections, train_quartiles, test_projections, test_quartiles)
                    results['ridge'] = [accuracy, precision, recall, f1, auc]
                    gene_to_metrics['projections']['positional_split'][current_gene] = results


                #RANDOM SPLIT 
                indices = list(range(len(gene_encodings)))
                np.random.shuffle(indices)
                train_idx = indices[:int(len(indices)*0.8)]
                test_idx = indices[int(len(indices)*0.8):]

                #sample train set size if specified
                if train_size is not None and len(train_idx) > train_size:
                    if train_size <= 1: #handle fraction
                        train_num = int(len(train_idx) * train_size)
                    else:
                        train_num = train_size
                    train_idx = np.random.choice(train_idx, size=train_num, replace=False).tolist()

                if len(train_idx) == 0 or len(test_idx) == 0:
                    print(f"Skipping gene {current_gene} for random split due to insufficient data after sampling")
                    should_evaluate=False
                
                train_encodings = [gene_encodings[i] for i in train_idx]
                train_projections = [gene_projections[i] for i in train_idx]
                train_quartiles = [gene_quartiles[i] for i in train_idx]
                
                if len(train_encodings) < 5:
                    print(f"Skipping gene {current_gene} for random split due to insufficient training data")
                    should_evaluate=False
                #train_similarities = [gene_similarities[i] for i in train_idx]
                #train_labels = [gene_labels[i] for i in train_idx]
                
                test_encodings = [gene_encodings[i] for i in test_idx]
                test_projections = [gene_projections[i] for i in test_idx]
                test_quartiles = [gene_quartiles[i] for i in test_idx]
                #test_similarities = [gene_similarities[i] for i in test_idx]
                #test_labels = [gene_labels[i] for i in test_idx]

                if len(set(train_quartiles)) < 2 or len(set(test_quartiles)) < 2:
                    print(f"Skipping gene {current_gene} for random split due to only one quartile present in train or test set")
                    should_evaluate=False

                if should_evaluate:
                    #projection results
                    results = {'knn': [], 'ridge': []}
                    #knn eval:
                    accuracy, precision, recall, f1, auc = knn_metrics(test_encodings, test_quartiles, train_encodings, train_quartiles)
                    results['knn'] = [accuracy, precision, recall, f1, auc]
                    #ridge eval:
                    accuracy, precision, recall, f1, auc = ridge_metrics(train_encodings, train_quartiles, test_encodings, test_quartiles)
                    results['ridge'] = [accuracy, precision, recall, f1, auc]
                    gene_to_metrics['baseline']['random_split'][current_gene] = results

                    #projection results
                    results = {'knn': [], 'ridge': []}
                    #knn eval:
                    accuracy, precision, recall, f1, auc = knn_metrics(test_projections, test_quartiles, train_projections, train_quartiles)
                    results['knn'] = [accuracy, precision, recall, f1, auc]
                    #ridge eval:
                    accuracy, precision, recall, f1, auc = ridge_metrics(train_projections, train_quartiles, test_projections, test_quartiles)
                    results['ridge'] = [accuracy, precision, recall, f1, auc]
                    gene_to_metrics['projections']['random_split'][current_gene] = results
                
            #reset for next gene
            current_gene = gene
            gene_encodings = []
            gene_projections = []
            #gene_similarities = []
            #gene_labels = []
            gene_quartiles = []
            gene_mutants = []
        #print(ohe_features)
        #print(ohe_features.shape)
        #print(type(ohe_features))

        #remove nans and stay consistent with quartiles
        nan_idx = np.where(np.isnan(ohe_features).any(axis=1))[0]
        #print(f"Removing {len(nan_idx)} features with nan values")
        ohe_features = np.delete(ohe_features, nan_idx, axis=0)
        projections = np.delete(projections, nan_idx, axis=0)
        quartiles = [quartiles[i] for i in range(len(quartiles)) if i not in nan_idx]
        mutants = [mutants[i] for i in range(len(mutants)) if i not in nan_idx]
        assert len(ohe_features) == len(quartiles) == len(mutants) == len(projections)
        gene_encodings.extend(ohe_features)
        gene_projections.extend(projections)
        gene_quartiles.extend(quartiles)
        gene_mutants.extend(mutants)

        #loss, similarities, distances, labels = loss_fn(torch.tensor(ohe_features, dtype=torch.float32), quartiles)

        #gene_similarities.extend(similarities)
        #gene_labels.extend(labels)
        #all_losses.append(loss.item())
        #all_similarities.extend(similarities)
        #all_distances.extend(distances)
        #all_labels.extend(labels)


    #save to json
    dict_dir = f'{RESULTS_DIR}/result_dicts'
    os.makedirs(dict_dir, exist_ok=True)
    with open(f'{dict_dir}/ohe_llr_metrics_{train_size:g}.json', 'w') as f:
        json.dump(gene_to_metrics, f)

    #acc, precision, recall, f1 = contrastive_metrics(all_similarities, all_labels)
    #auc = roc_auc_score(all_labels, all_similarities)
    #with open(RESULTS_FILE, 'a') as f:
    #    f.write(f'{RUN_NAME}_OHE+LLR_baseline,{np.mean(all_losses)},{acc},{precision},{recall},{f1},{auc}\n')
    
    
    #average metrics across all genes
    with open(RESULTS_FILE, 'a') as f:
        for split_type in ['random_split', 'positional_split']:
            for model in ['baseline', 'projections']:
                for classifier in ['knn', 'ridge']:
                    acc = np.mean([gene_to_metrics[model][split_type][gene][classifier][0] for gene in gene_to_metrics[model][split_type]])
                    precision = np.mean([gene_to_metrics[model][split_type][gene][classifier][1] for gene in gene_to_metrics[model][split_type]])
                    recall = np.mean([gene_to_metrics[model][split_type][gene][classifier][2] for gene in gene_to_metrics[model][split_type]])
                    f1 = np.mean([gene_to_metrics[model][split_type][gene][classifier][3] for gene in gene_to_metrics[model][split_type]])
                    auc = np.mean([gene_to_metrics[model][split_type][gene][classifier][4] for gene in gene_to_metrics[model][split_type]])
                    
                    f.write(f'{RUN_NAME}_{model}_{classifier}_{split_type}_{train_size:g},-,{acc},{precision},{recall},{f1},{auc}\n')

    return gene_to_metrics
    

def classification_comparison_by_train_size(projection_net, dataloader, device, train_sizes=[.05, .1, .2, .4, .6, .8]):
    #run classification comparison at different train sizes for OHE+LLR baseline vs learned projections
    #then plot performance vs train size

    plot_dir = f'{RESULTS_DIR}/train_size_plots'
    os.makedirs(plot_dir, exist_ok=True)

    #precompute:
    batches = []
    for batch in tqdm(dataloader, desc="OHE LLR Baseline"):
        batch_data = {'quartiles': [], 'ohe_features': [], 'projections': [], 'mutants': [], 'genes': []}
        quartiles = batch['quartiles']
        ohe_features = batch['ohe_features']
        projections = projection_net(batch).cpu().detach().numpy()
        mutants = batch['mutants']

        assert len(set(batch['genes'])) == 1 #should only be used with gene-aware loader
        gene = batch['genes'][0]

        batch_data['quartiles'] = (quartiles)
        batch_data['ohe_features'] = (ohe_features)
        batch_data['projections'] = (projections)
        batch_data['mutants'] = (mutants)
        batch_data['genes'] = ([gene] * len(projections))
        batches.append(batch_data)

    dicts = {}
    for train_size in train_sizes:
        print(f'Calculating metrics for train size: {train_size}')
        dicts[train_size] = ohe_llr_baseline(batches, projection_net, train_size=train_size)
    
    #plot results
    for split_type in ['random_split', 'positional_split']:
        for classifier in ['knn', 'ridge']:
            aucs = {'baseline': [], 'projections': []}
            accs = {'baseline': [], 'projections': []}
            for model in ['baseline', 'projections']:
                
                for train_size in train_sizes:
                    acc = np.mean([dicts[train_size][model][split_type][gene][classifier][0] for gene in dicts[train_size][model][split_type]])
                    auc = np.mean([dicts[train_size][model][split_type][gene][classifier][4] for gene in dicts[train_size][model][split_type]])
                    aucs[model].append(auc)
                    accs[model].append(acc)
                
            #plot aucs
            plt.figure()
            plt.plot(train_sizes, aucs['baseline'], label='OHE+LLR Baseline', marker='o')
            plt.plot(train_sizes, aucs['projections'], label='Learned Projections', marker='o')
            plt.xlabel('Training Set Size')
            plt.ylabel('Average AUC')
            plt.title(f'AUC vs Training Set Size ({classifier}, {split_type})')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.savefig(f'{plot_dir}/auc_vs_train_size_{classifier}_{split_type}.png')

def get_ohe_features(wt_sequences, mutants):
    #to be used in DataLoader / collate_batch

    #checks
    if len(wt_sequences) != len(mutants):
        raise ValueError('wt_sequences and mutants must have the same length')
    if len(set(wt_sequences)) != 1:
        raise ValueError('wt_sequences must all be the same for GENE AWARE data loader - needs new implementation if we want to change this, but relevant')
    wt_sequence = wt_sequences[0]
    
    #constants
    MISSENSE_PATTERN = re.compile('([A-Z])(\d+)([A-Z])')
    UNIQUE_AAS = list('ACDEFGHIKLMNPQRSTVWY')
    aa_to_index = {aa: i for i, aa in enumerate(UNIQUE_AAS)}

    #make features
    ohe_features = np.zeros((len(mutants), len(wt_sequence), len(UNIQUE_AAS)), dtype = np.int8)

    with open(os.devnull, 'w') as fnull, redirect_stdout(fnull), redirect_stderr(fnull):
        llr_scores = calc_esm_llr_scores(wt_sequence)
    llr_scores_ordered = [llr_scores[mutant] if mutant in llr_scores else np.nan for mutant in mutants]
    llr_scores_reshaped = np.array(llr_scores_ordered).reshape(-1, 1)

    #start with 1s at each WT aa
    for j, aa in enumerate(wt_sequence):
        ohe_features[:, j, aa_to_index[aa]] = 1

    for i, mut_name in enumerate(mutants):
        #print(f'Processing mutation {mut_name}')
        #handle multiple mutations - this isn't really necessary bc llr cant handle multiple, and these will be removed anyway - but lets keep the logic for now
        if ':' in mut_name:
            mut_names = mut_name.split(':')
        else:
            mut_names = [mut_name]

        for mut_name in mut_names:
            matches = MISSENSE_PATTERN.findall(mut_name)
            if not matches:
                continue
            ref_aa, pos, alt_aa = matches[0]
            j = int(pos) - 1
            ohe_features[i, j, aa_to_index[ref_aa]] = 0
            ohe_features[i, j, aa_to_index[alt_aa]] = 1 #change wt aa to alt at mutated position

    ohe_features = ohe_features.reshape(len(mutants), -1) #flatten from 3d (n_mutants, seq_len, n_aas) to 2d (n_mutants, seq_len * n_aas)
    ohe_features = np.concatenate([llr_scores_reshaped, ohe_features], axis = 1) #add llr score to beginning
    #print(ohe_features.shape)
    #there will be NaNs if there are two mutated positions (A23Y:A27R), we need to remove these later to stay consistent with quartiles
    return ohe_features

def llr_threshold_performance(test_loader):
    #split-by-gene baseline evaluation using LLR score

    test_llr = []
    test_quartiles = []
    for batch in tqdm(test_loader):
        test_llr.extend(batch['ohe_features'][:, 0])
        test_quartiles.extend(batch['quartiles'])

    #remove nans
    test_llr = np.array(test_llr)
    nan_idx = np.isnan(test_llr)
    test_llr = test_llr[~nan_idx]
    test_quartiles = np.array(test_quartiles)[~nan_idx]
    test_quartiles = [1 if q=='high' else 0 for q in test_quartiles]

    auc = roc_auc_score(test_quartiles, test_llr)

    with open(RESULTS_FILE, 'a') as f:
        f.write(f'{RUN_NAME}_LLR_alone,-,-,-,-,-,{auc}\n')
 

def train(projection_net, loss_fn, train_loader, test_loader, optimizer, device):
    
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    train_aucs = []
    val_aucs = []

    best_val_loss = float('inf')
    best_val_auc = float('-inf')
    patience_counter = 0
    best_model_state = None
    
    print(f"\n{'='*80}")
    print("STARTING TRAINING")
    print(f"{'='*80}\n")

    for epoch in range(NUM_EPOCHS):
        print(f"\nEpoch {epoch+1}/{NUM_EPOCHS}")
        #train
        train_loss, train_similarities, train_labels_epoch, train_dists, train_quartiles, train_projections = train_epoch(
            projection_net, loss_fn, train_loader, optimizer, device
        )

        #eval
        val_loss, val_similarities, val_labels_epoch, val_dists, val_quartiles, val_projections = evaluate_model(
            projection_net, loss_fn, test_loader, device
        )

        #metrics
        
        #train_acc, train_precision, train_recall, train_f1 = kmeans_metrics(train_projections, train_quartiles, n_clusters=2)
        #val_acc, val_precision, val_recall, val_f1 = kmeans_metrics(val_projections, val_quartiles, n_clusters=2)
        #val_acc, val_precision, val_recall, val_f1 = logreg_metrics(train_projections, train_quartiles, val_projections, val_quartiles)

        val_acc, val_precision, val_recall, val_f1 = contrastive_metrics(val_similarities, val_labels_epoch)
        train_acc, train_precision, train_recall, train_f1 = contrastive_metrics(train_similarities, train_labels_epoch)
        train_auc = roc_auc_score(train_labels_epoch, train_similarities)
        val_auc = roc_auc_score(val_labels_epoch, val_similarities)

        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        train_aucs.append(train_auc)
        val_aucs.append(val_auc)

        if val_auc > best_val_auc:
            best_val_auc = val_auc
            patience_counter = 0
            best_model_state = projection_net.state_dict().copy()
            best_optimizer_state = optimizer.state_dict().copy()
            print(f" Epoch {epoch+1}: New best val auc: {best_val_auc:.4f}")
        else:
            patience_counter += 1

        #if (epoch + 1) % 5 == 0:
        print(f"Epoch {epoch+1}/{NUM_EPOCHS}")
        print(f"  Train Loss: {train_loss:.4f}") #, Train Acc: {train_acc:.4f}")
        print(f"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
        print(f"  Patience: {patience_counter}/{PATIENCE}")
        print(f"  Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}")
        if USE_LEARNABLE:
            print(f"  Alpha: {loss_fn.alpha.item():.4f}, Beta: {loss_fn.beta.item():.4f}")

        if (epoch + 1) % 20 == 0:
            print("\n=== Distance Clustering Analysis ===")
            similar_mean, dissimilar_mean, separation = plot_distance_clustering(
                train_dists, train_labels_epoch, f"Training - Epoch {epoch+1}", final=False
            )
            print(f"Separation: {separation:.4f}\n")

        if patience_counter >= PATIENCE:
            print(f"\n Early stopping at epoch {epoch+1}")
            break

    print("\n" + "="*80)
    print("TRAINING COMPLETE")
    print("="*80 + "\n")

    print("\n=== Saving Model ===")
    torch.save({
        'model_state_dict': best_model_state,
        'optimizer_state_dict': best_optimizer_state,
        'train_losses': train_losses,
        'val_losses': val_losses,
        'config': {
            'distance_metric': DISTANCE_METRIC,
            'hidden_dims': HIDDEN_DIMS,
            'learning_rate': LEARNING_RATE,
            'best_val_auc': best_val_auc
        }
    }, f'{RESULTS_DIR}/projection_head.pt')
    print(f" Model saved to '{RESULTS_DIR}/projection_head.pt'")

    plot_training_metrics(train_losses, val_losses, train_aucs, val_aucs)

    return best_model_state



        
        


def main():
    print("="*80)
    print(f"Running Contrastive Learning for {RUN_NAME}")
    print("="*80)
    #print(f"Embeddings Path: {EMBEDDINGS_PATH}")
    print(f"Data Path: {DATA_PATH}")
    print(f"Device: {device}")
    print(f"Distance Metric: {DISTANCE_METRIC}")
    print(f"Learnable Transformation: {USE_LEARNABLE}")
    print(f"Output Normalization: {NORMALIZE_OUTPUT}")
    print("="*80)

    """try:
        from google.colab import drive
        drive.mount('/content/drive')
    except:
        print("Not in Colab environment, skipping drive mount")"""

    #load and preprocess data
    df = load_and_preprocess_data(DATA_PATH)
    print(f'Initial mutated sequence length distribution: {df["mutated_sequence"].str.len().describe()}')
    initial_length = len(df)
    df = df[df['mutated_sequence'].str.len() <= args.esm_max_length]
    filtered_count = initial_length - len(df)
    if filtered_count > 0:
        print(f"Filtered {filtered_count} sequences with length > {args.esm_max_length}")
    #df = df.sample(10000, random_state=42) #for testing

    if args.normalize_to_wt:
        gene_to_wt = pd.read_csv(args.metadata_path)
        gene_to_wt = gene_to_wt.set_index('DMS_filename')['target_seq'].to_dict()
    else:
        gene_to_wt = None

    #create train/test split
    train_df, test_df = create_train_test_split(df, split_by_gene=args.split_by_gene, split_by_position=args.split_by_position, test_size=0.2)

    #extract data
    train_seqs = train_df['mutated_sequence'].tolist()
    train_quarts = train_df['quartile'].tolist()
    train_dms = train_df['DMS_score'].tolist()
    train_genes = train_df['filename'].tolist()

    test_seqs = test_df['mutated_sequence'].tolist()
    test_quarts = test_df['quartile'].tolist()
    test_dms = test_df['DMS_score'].tolist()
    test_genes = test_df['filename'].tolist()
    if args.ohe_baseline:
        test_mutants = test_df['mutant'].tolist()
        train_mutants = train_df['mutant'].tolist()
    else:
        test_mutants = None
        train_mutants = None

    print(f'train seq length distribution: {pd.Series(train_seqs).str.len().describe()}')
    print(f'test seq length distribution: {pd.Series(test_seqs).str.len().describe()}')

    #init h5 file for embeddings
    if args.embeddings_path is not None:
        global ESMEmbeddingLoader
        ESMEmbeddingLoader = h5_utils.EmbeddingLoader(args.embeddings_path, len(train_seqs)+len(test_seqs)+filtered_count, embed_dim=args.input_dim)
    else:
        raise ValueError("Embeddings path must be specified")
    if args.ohe_baseline:
        global OHEEmbeddingLoader
        OHEEmbeddingLoader = h5_utils.EmbeddingLoader(args.ohe_embeddings_path, len(train_seqs)+len(test_seqs)+filtered_count, embed_dim=20*args.esm_max_length)

    #create datasets
    if args.split_by_gene:
        assert set(train_genes).isdisjoint(set(test_genes))
    else:
        print('WARNING: NOT splitting train/test set by gene')
    train_dataset = DMSContrastiveDataset(train_seqs, train_quarts, train_dms,
                                          train_genes, train_mutants)
    test_dataset = DMSContrastiveDataset(test_seqs, test_quarts, test_dms,
                                         test_genes, test_mutants)

    #create data loaders
    if args.same_gene_batch:
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, gene_to_wt = gene_to_wt, shuffle=True, gene_aware=True)
        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, gene_to_wt = gene_to_wt, shuffle=False, gene_aware=True)
    else:
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, gene_to_wt = gene_to_wt, shuffle=True, gene_aware=False)
        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, gene_to_wt = gene_to_wt, shuffle=False, gene_aware=False)
        gene_aware_test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, gene_to_wt=gene_to_wt, shuffle=False, gene_aware=True)
        gene_aware_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, gene_to_wt=gene_to_wt, shuffle=True, gene_aware=True)


    print(f"\n Data loaders created")
    print(f"   Train batches: ~{len(train_loader)}")
    print(f"   Test batches: ~{len(test_loader)}")

    #check first batch
    first_batch = next(iter(train_loader))
    quartiles_in_batch = first_batch['quartiles']
    genes_in_batch = first_batch['genes']
    high_count = sum(1 for q in quartiles_in_batch if q == 'high')
    low_count = sum(1 for q in quartiles_in_batch if q == 'low')
    unique_genes = len(set(genes_in_batch))
    print(f"\n First batch check:")
    print(f"   Batch size: {len(quartiles_in_batch)}")
    print(f"   High: {high_count}, Low: {low_count}")
    print(f"   Unique genes in batch: {unique_genes} (should be 1 for gene-aware)")

    #init model
    projection_net = ContrastiveNetwork(
        input_dim=args.input_dim,
        hidden_dims=HIDDEN_DIMS,
        normalize_output=NORMALIZE_OUTPUT,
        esm_layer=args.esm_layer,
        normalize_to_wt=args.normalize_to_wt
    ).to(device)

    loss_fn = ContrastiveLoss(
        distance_metric=DISTANCE_METRIC,
        use_learnable=USE_LEARNABLE
    )

    optimizer = optim.Adam(projection_net.parameters(), lr=LEARNING_RATE)

    print(f"\n Model initialized")
    print(f"   Parameters: {sum(p.numel() for p in projection_net.parameters()):,}")
    if USE_LEARNABLE:
        print(f"   Learnable alpha: {loss_fn.alpha.item():.4f}")
        print(f"   Learnable beta: {loss_fn.beta.item():.4f}")


    if args.model_path is not None:
        print(f"\n Loading model from {args.model_path}")
        checkpoint = torch.load(args.model_path, map_location=device)
        projection_net.load_state_dict(checkpoint['model_state_dict'])
    else:
        best_model_state = train(projection_net, loss_fn, train_loader, test_loader, optimizer, device)
        print("\n Restoring best model...")
        projection_net.load_state_dict(best_model_state)

    if args.ohe_baseline:
        print("\n=== BASELINE vs PROJECTION EVALUATION ===")
        #llr_threshold_performance(gene_aware_test_loader)
        #ohe_llr_baseline(loss_fn, gene_aware_test_loader)
        classification_comparison_by_train_size(projection_net, gene_aware_test_loader, device, train_sizes=[.01, .025, .05, .1, .2, .4, .6, .8, 1.0])
        return

    print("\n=== FINAL EVALUATION ===")

    #different-gene batch evaluation
    print('main batch evaluation')
    test_loss, test_similarities, test_labels, test_dists, test_quartiles, test_projections = evaluate_model(
        projection_net, loss_fn, test_loader, device
    )
    train_loss, train_similarities, train_labels, train_dists, train_quartiles, train_projections = evaluate_model(
        projection_net, loss_fn, train_loader, device
    )
    #test_acc, test_precision, test_recall, test_f1 = contrastive_metrics(test_similarities, test_labels)
    knn_acc, knn_precision, knn_recall, knn_f1 = knn_metrics(train_projections, train_quartiles, test_projections, test_quartiles)

    test_auc = roc_auc_score(test_labels, test_similarities) #auc based on similarities

    """
    #Gene-aware evaluation
    print('gene-aware batch evaluation')
    gene_aware_final_loss, gene_aware_final_similarities, gene_aware_final_labels, gene_aware_final_dists, gene_aware_final_quartiles, gene_aware_final_projections = evaluate_model(
        projection_net, loss_fn, gene_aware_test_loader, device
    )
    gene_aware_test_acc, gene_aware_test_precision, gene_aware_test_recall, gene_aware_test_f1 = contrastive_metrics(gene_aware_final_similarities, gene_aware_final_labels)
    gene_aware_test_auc = roc_auc_score(gene_aware_final_labels, gene_aware_final_similarities)

    #original ESM evaluation - normalize to wt
    if args.normalize_to_wt:
        esm_only_model_normalize = ContrastiveNetwork(
            input_dim=args.input_dim,
            hidden_dims=HIDDEN_DIMS,
            normalize_output=NORMALIZE_OUTPUT,
            esm_layer=args.esm_layer,
            esm_only=True,
            normalize_to_wt=True
        ).to(device)
        print('og esm embeddings evaluation - main batch type - normalize to wt')
        original_normalize_test_loss, original_normalize_test_similarities, original_normalize_test_labels, original_normalize_test_dists, original_normalize_test_quartiles, original_normalize_test_projections = evaluate_model(
            esm_only_model_normalize, loss_fn, test_loader, device
        )
        original_normalize_test_acc, original_normalize_test_precision, original_normalize_test_recall, original_normalize_test_f1 = contrastive_metrics(original_normalize_test_similarities, original_normalize_test_labels)
        original_normalize_test_auc = roc_auc_score(original_normalize_test_labels, original_normalize_test_similarities)

        print('og esm embeddings evaluation - gene-aware batch type - normalize to wt')
        original_normalize_gene_aware_test_loss, original_normalize_gene_aware_test_similarities, original_normalize_gene_aware_test_labels, original_normalize_gene_aware_test_dists, original_normalize_gene_aware_test_quartiles, original_normalize_gene_aware_test_projections = evaluate_model(
            esm_only_model_normalize, loss_fn, gene_aware_test_loader, device
        )
        original_normalize_gene_aware_test_acc, original_normalize_gene_aware_test_precision, original_normalize_gene_aware_test_recall, original_normalize_gene_aware_test_f1 = contrastive_metrics(original_normalize_gene_aware_test_similarities, original_normalize_gene_aware_test_labels)
        original_normalize_gene_aware_test_auc = roc_auc_score(original_normalize_gene_aware_test_labels, original_normalize_gene_aware_test_similarities)
    else:
        original_normalize_test_loss = '-'
        original_normalize_test_similarities = '-'
        original_normalize_test_labels = '-'
        original_normalize_test_dists = '-'
        original_normalize_test_quartiles = '-'
        original_normalize_test_projections = '-'
        original_normalize_test_acc = '-'
        original_normalize_test_precision = '-'
        original_normalize_test_recall = '-'
        original_normalize_test_f1 = '-'
        original_normalize_test_auc = '-'


    #otiginal ESM eval - NOT normalizing to wt
    esm_only_model_no_normalize = ContrastiveNetwork(
        input_dim=args.input_dim,
        hidden_dims=HIDDEN_DIMS,
        normalize_output=NORMALIZE_OUTPUT,
        esm_layer=args.esm_layer,
        esm_only=True,
        normalize_to_wt=False
    ).to(device)
    print('og esm embeddings evaluation - main batch type - not normalize to wt')
    original_test_loss, original_test_similarities, original_test_labels, original_test_dists, original_test_quartiles, original_test_projections = evaluate_model(
        esm_only_model_no_normalize, loss_fn, test_loader, device
    )
    original_test_acc, original_test_precision, original_test_recall, original_test_f1 = contrastive_metrics(original_test_similarities, original_test_labels)
    original_test_auc = roc_auc_score(original_test_labels, original_test_similarities)

    print('og esm embeddings evaluation - gene-aware batch type - not normalize to wt')
    original_gene_aware_test_loss, original_gene_aware_test_similarities, original_gene_aware_test_labels, original_gene_aware_test_dists, original_gene_aware_test_quartiles, original_gene_aware_test_projections = evaluate_model(
        esm_only_model_no_normalize, loss_fn, gene_aware_test_loader, device
    )
    original_gene_aware_test_acc, original_gene_aware_test_precision, original_gene_aware_test_recall, original_gene_aware_test_f1 = contrastive_metrics(original_gene_aware_test_similarities, original_gene_aware_test_labels)
    original_gene_aware_test_auc = roc_auc_score(original_gene_aware_test_labels, original_gene_aware_test_similarities)

    """
    print(f"\nTest Metrics:")
    #print(f"  Loss: {test_loss:.4f}")
    print(f"  Accuracy: {knn_acc:.4f}")
    print(f"  Precision: {knn_precision:.4f}")
    print(f"  Recall: {knn_recall:.4f}")
    print(f"  F1: {knn_f1:.4f}")
    print(f"  AUC: {test_auc:.4f}")



    with open(RESULTS_FILE, 'a') as f:
        f.write(f'{RUN_NAME},{knn_acc},{knn_precision},{knn_recall},{knn_f1},{test_auc}\n')
        #f.write(f'{RUN_NAME}_gene_aware_eval,-,{gene_aware_test_acc},{gene_aware_test_precision},{gene_aware_test_recall},{gene_aware_test_f1},{gene_aware_test_auc}\n')
        #f.write(f'{RUN_NAME}_og_esm_normalize,-,{original_normalize_test_acc},{original_normalize_test_precision},{original_normalize_test_recall},{original_normalize_test_f1},{original_normalize_test_auc}\n')
        #f.write(f'{RUN_NAME}_og_esm_normalize_gene_aware,-,{original_normalize_gene_aware_test_acc},{original_normalize_gene_aware_test_precision},{original_normalize_gene_aware_test_recall},{original_normalize_gene_aware_test_f1},{original_normalize_gene_aware_test_auc}\n')
        #f.write(f'{RUN_NAME}_og_esm_no_normalize,-,{original_test_acc},{original_test_precision},{original_test_recall},{original_test_f1},{original_test_auc}\n')
        #f.write(f'{RUN_NAME}_og_esm_no_normalize_gene_aware,-,{original_gene_aware_test_acc},{original_gene_aware_test_precision},{original_gene_aware_test_recall},{original_gene_aware_test_f1},{original_gene_aware_test_auc}\n')


    print(f"\nDistance Statistics:")
    print(f"  Mean: {np.mean(test_dists):.4f}")
    print(f"  Std: {np.std(test_dists):.4f}")
    print(f"  Min: {np.min(test_dists):.4f}")
    print(f"  Max: {np.max(test_dists):.4f}")

    print("\n=== Final Distance Clustering ===")
    plot_distance_clustering(test_dists, test_labels, "Final Test Set", final=True)

    """

    print("\n=== Embedding Visualization ===")
    sample_size = min(500, len(test_seqs))
    sample_indices = np.random.choice(len(test_seqs), sample_size, replace=False)

    sample_seqs = [test_seqs[i] for i in sample_indices]
    sample_dms = [test_dms[i] for i in sample_indices]

    sample_embeddings = load_embeddings_h5(sample_seqs)

    visualize_embeddings_tsne(sample_embeddings, sample_dms,
                              f"Original ESM Layer {args.esm_layer} Embeddings (DMS Colored)")

    projected_embeddings = torch.tensor(test_projections)

    visualize_embeddings_tsne(projected_embeddings, sample_dms,
                              "Projected Embeddings (DMS Colored)")
    """

    h5_utils.close_h5()

if __name__ == '__main__':
    main()

print('Pipeline completed successfully')

"""
import pandas as pd

# Load the data
df = pd.read_csv(DATA_PATH)

print("DMS Score Statistics:")
print(df['DMS_score'].describe())
print(f"\nMin: {df['DMS_score'].min()}")
print(f"Max: {df['DMS_score'].max()}")
print(f"Range: {df['DMS_score'].max() - df['DMS_score'].min()}")

# Check for outliers
print(f"\nValues > 10: {(df['DMS_score'] > 10).sum()}")
print(f"Values > 20: {(df['DMS_score'] > 20).sum()}")
print(f"Values > 40: {(df['DMS_score'] > 40).sum()}")

# Show some high values
print("\nTop 10 highest DMS scores:")
print(df.nlargest(10, 'DMS_score')[['DMS_score', 'filename', 'mutant']])

# Check which genes have extreme DMS scores
extreme_threshold = 10

extreme_rows = df[df['DMS_score'] > extreme_threshold]
print(f"Rows with DMS_score > {extreme_threshold}: {len(extreme_rows)}")
print("\nGenes with extreme values:")
print(extreme_rows.groupby('filename')['DMS_score'].agg(['count', 'min', 'max', 'mean']))

# Show the actual extreme values
print("\nTop 20 highest DMS scores:")
print(df.nlargest(20, 'DMS_score')[['DMS_score', 'filename', 'mutant', 'mutated_sequence']])

"""
